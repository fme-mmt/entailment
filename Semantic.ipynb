{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "\n",
    "\n",
    "from nltk import Tree\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_nltk_tree(node):\n",
    "\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "\n",
    "        print(\"%s%s\"%(\n",
    "\n",
    "             node.lemma_, # or \"node.orth_,\" with original form\n",
    "\n",
    "             ','))\n",
    "\n",
    "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"%s%s\"%(\n",
    "\n",
    "             node.lemma_, # or \"node.orth_,\" with original form\n",
    "\n",
    "             ';'))\n",
    "\n",
    "        return node.orth_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_nltk_tree(node):\n",
    "\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "\n",
    "        print(\"%s%s\"%(\n",
    "\n",
    "             node.lemma_, # or \"node.orth_,\" with original form\n",
    "\n",
    "             ','))\n",
    "\n",
    "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"%s%s\"%(\n",
    "\n",
    "             node.lemma_, # or \"node.orth_,\" with original form\n",
    "\n",
    "             ';'))\n",
    "\n",
    "        return node.orth_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentence(nlp, sentence):\n",
    "\n",
    "  \"\"\"Parse unicode sentence into a NLTK tree\n",
    "\n",
    "  using the spacy parser\"\"\"\n",
    "\n",
    "  doc = nlp(sentence)\n",
    "\n",
    "  trees = [tree_sentence(s.root) for s in doc.sents]\n",
    "\n",
    "  assert len(trees) == 1\n",
    "\n",
    "  return trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_sentence(node):\n",
    "\n",
    "    from nltk import Tree\n",
    "\n",
    "    if node.pos_ in ('VERB', 'NOUN', 'DET'):\n",
    "\n",
    "        tag = node.lemma_\n",
    "\n",
    "    else:\n",
    "\n",
    "        tag = node.orth_\n",
    "\n",
    "\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "\n",
    "        return Tree(tag, [tree_sentence(child) for child in node.children])\n",
    "\n",
    "    else:\n",
    "\n",
    "        return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tree(nlp, sentence):\n",
    "\n",
    "    \"\"\"Parse tag sentence into a NLTK tree\n",
    "\n",
    "    using the spacy parser\"\"\"\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    trees = [tree_tree(s.root) for s in doc.sents]\n",
    "\n",
    "    assert len(trees) == 1\n",
    "\n",
    "    return trees[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_tree(node):\n",
    "\n",
    "    from nltk import Tree\n",
    "\n",
    "\n",
    "    tag = node.tag_\n",
    "\n",
    "\n",
    "    if node.n_lefts + node.n_rights > 0:\n",
    "\n",
    "        return Tree(tag, [tree_tree(child) for child in node.children])\n",
    "\n",
    "    else:\n",
    "\n",
    "        return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical(s):\n",
    "\n",
    "  if (s == 'every' or s == 'all'):\n",
    "\n",
    "      return 'FORALL'\n",
    "\n",
    "  else:\n",
    "\n",
    "      return 'EXISTS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propi(s):\n",
    "\n",
    "    if (s == 'andreu' or s=='mickey' or s=='jordi' or s=='alejandro'):\n",
    "\n",
    "        return 'EXISTS'\n",
    "\n",
    "    else: return 'FORALL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conjuncio(s):\n",
    "\n",
    "    if s == 'FORALL':\n",
    "\n",
    "        return 'IMPLY'\n",
    "\n",
    "    else: return 'AND'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic(frase,variable):\n",
    "\n",
    "  sentences = []\n",
    "\n",
    "  trees = []\n",
    "\n",
    "  new_text = frase\n",
    "\n",
    "  sentences.append(parse_sentence(nlp, (new_text)))\n",
    "\n",
    "  trees.append(parse_tree(nlp, (new_text)))\n",
    "\n",
    "\n",
    "  for s in sentences:\n",
    "\n",
    "      print(s.pretty_print())\n",
    "\n",
    "\n",
    "  for t in trees:\n",
    "\n",
    "    print(t)\n",
    "\n",
    "\n",
    "  for i in range(len(t)-1): \n",
    "    if (i>0 and t[i-1]=='DT' and t[i]=='JJ'): t[i]='NN'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  res = []\n",
    "\n",
    "  count = 0\n",
    "\n",
    "  count2 = 0\n",
    "\n",
    "  count4 = 0\n",
    "\n",
    "\n",
    "  index = 1\n",
    "\n",
    "\n",
    "  for i in range(len(sentences[0])):\n",
    "\n",
    "      if (type(sentences[0][0])==str and type(sentences[0][1])==str and count==0):\n",
    "\n",
    "          res.append(propi(sentences[0][0]))\n",
    "\n",
    "          res.append(variable)\n",
    "\n",
    "          index +=1\n",
    "\n",
    "          res.append([])\n",
    "\n",
    "          count += 1\n",
    "\n",
    "          res[index].append(conjuncio(propi(sentences[0][0])))\n",
    "\n",
    "          res[index].append([sentences[0][0],variable])\n",
    "\n",
    "      if (type(sentences[0][0])==str and type(sentences[0][1])!=str and count==0):\n",
    "\n",
    "          res.append(propi(sentences[0][0]))\n",
    "\n",
    "          res.append(variable)\n",
    "\n",
    "          index +=1\n",
    "\n",
    "          res.append([])\n",
    "\n",
    "          count += 1\n",
    "\n",
    "          res[index].append(conjuncio(propi(sentences[0][0])))\n",
    "\n",
    "          res[index].append([sentences[0][0],variable])\n",
    "\n",
    "      if (type(sentences[0][i])==str and i!=0):\n",
    "        if (sentences[0][i] == 'not'): \n",
    "            \n",
    "            res[index].append(['not'+'_'+sentences[0][i+1],variable])            \n",
    "            count4 = 1\n",
    "        elif count4 != 1: res[index].append([sentences[0][i],variable])\n",
    "\n",
    "      if (type(sentences[0][i])!=str):\n",
    "\n",
    "          if(t[i].label()=='NN' or t[i].label()=='NNS'):\n",
    "\n",
    "              for j in range(len(sentences[0][i])):\n",
    "\n",
    "                  if(t[i][j]=='DT' and count == 0):\n",
    "\n",
    "                      res.append(categorical(sentences[0][i][j]))\n",
    "\n",
    "                      res.append(variable)\n",
    "\n",
    "                      index +=1\n",
    "\n",
    "                      res.append([])\n",
    "\n",
    "                      res[index].append(conjuncio(categorical(sentences[0][0][0])))\n",
    "                        \n",
    "                      count += 1\n",
    "\n",
    "                  else:\n",
    "\n",
    "                      if (t[i][j]!='DT'):\n",
    "\n",
    "                          res[index].append([sentences[0][i][j],variable])\n",
    "\n",
    "              res[index].append([sentences[0][i].label(),variable])\n",
    "\n",
    "          else:\n",
    "\n",
    "              for j in range(len(sentences[0][i])):\n",
    "\n",
    "                  if sentences[0][i][j] == 'not':\n",
    "\n",
    "                      count2 = 1\n",
    "\n",
    "                      res[index].append([sentences[0][i][j]+'_'+sentences[0][i].label(),variable])\n",
    "\n",
    "                  if t[i][j] == 'JJ':\n",
    "\n",
    "                      res[index].append([sentences[0][i][j],variable])\n",
    "\n",
    "                      if count2 == 0:\n",
    "\n",
    "                          res[index].append([sentences[0][i].label(),1])\n",
    "\n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase:  andreu is not ugly\n",
      "Frase:  andreu is handsome\n",
      "Frase:  \n",
      "        be     \n",
      "   _____|___    \n",
      "andreu not ugly\n",
      "\n",
      "None\n",
      "(VBZ DT RB JJ)\n",
      "        be         \n",
      "   _____|_____      \n",
      "andreu     handsome\n",
      "\n",
      "None\n",
      "(VBZ DT JJ)\n",
      "[['EXISTS', 1, ['AND', ['andreu', 1], ['not_ugly', 1]]], ['EXISTS', 2, ['AND', ['andreu', 2], ['handsome', 2]]]]\n"
     ]
    }
   ],
   "source": [
    "premises = []\n",
    "\n",
    "tesi= ''\n",
    "\n",
    "resultat = []\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "  frase = input('Frase:  ')\n",
    "\n",
    "  if frase == '': break\n",
    "\n",
    "  premises.append(frase)\n",
    "\n",
    "\n",
    "tesi = premises[len(premises)-1]\n",
    "\n",
    "del premises[len(premises)-1]\n",
    "\n",
    "variable = 1\n",
    "\n",
    "for i in range(len(premises)):\n",
    "\n",
    "  resultat.append(semantic(premises[i],variable))\n",
    "  variable = variable + 1\n",
    "\n",
    "resultat.append(semantic(tesi,variable))\n",
    "\n",
    "print(resultat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
